{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Python_Crawling2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/finddme/Python/blob/master/Python_Crawling2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "ba6970f0"
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Continuous-Crawling\" data-toc-modified-id=\"Continuous-Crawling-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Continuous Crawling</a></span></li></ul></div>"
      ],
      "id": "ba6970f0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0255b13f"
      },
      "source": [
        "## Continuous Crawling\n",
        "\n",
        "연속적인 크롤링을 해보자.\n",
        "\n",
        "이 블로그에 있는 모든 포스트의 제목들을 추출해보자"
      ],
      "id": "0255b13f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bca740ab"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "id": "bca740ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf231090",
        "outputId": "63c5874d-108b-4d11-ab4e-c14bbde491e1"
      },
      "source": [
        "'''\n",
        "함수를 만들어서 블로그에 있는 포스트 제목들을 모두 추출하자\n",
        "# 1. 제목을 title1 배열에 담아줄 것이기 때문에 빈 배열을 미리 만들어 놓는다.\n",
        "# 2. 카테고리 전체를 보여주는 페이지의 주소에 get방식으로 접근한다.\n",
        "     해당 페이지까지 접근하는 요청 객체를 req1로 생성한다.\n",
        "# 3. 위 페이지의 html문서를 가져온다.\n",
        "# 4. soup1이라는 변수에 BeautifulSoup을 통해 해당 html문서(html1)를 파싱한 결과를 담는다.\n",
        "# 5. 페이지 소스코드를 보면 제목들이 <div class=\"tags-expo-section\">에 담기는 것을\n",
        "     확인할 수 있다. 그래서 모든 'div'태그를 찾아내서 해당 태그의 'class' 속성의 값이\n",
        "     tags-expo-section인 것들을 다 찾아라\n",
        "# 6. 앞서 찾아낸 것들을 하나씩 돌면서 검색을 시작할거다\n",
        "# 7. 내부에 존재하는 모든 'a'태그(여기에 제목 적혀있다)를 검색해서 links1에 담는다\n",
        "# 8. links1에 담긴 a태그들을 하나씩 돌면서\n",
        "# 9. title1에 a태그 안에 있는 내용(text)를 담는다\n",
        "# 10. 아까 만든 titles1 배열에 title1을 붙여서 넣는다\n",
        "# 11. titles1 배열을 반환한다.\n",
        "'''\n",
        "def get_all_categories():\n",
        "    titles1 = [] # 1\n",
        "    req1 = requests.get(\"https://finddme.github.io/\") # 2\n",
        "    html1 = req1.text # 3\n",
        "    soup1 = BeautifulSoup(html1, \"html.parser\") # 4\n",
        "    divs1 = soup1.findAll('div',{\"class\":\"tags-expo-section\"}) # 5\n",
        "    for div1 in divs1: # 6\n",
        "        links1 = div1.findAll('a') # 7\n",
        "        for link1 in links1: # 8\n",
        "            title1 = link1.text # 9\n",
        "            titles1.append(title1) # 10\n",
        "    return titles1 # 11\n",
        "\n",
        "# 이제 만든 함수가 제목들을 잘 가져오는지 확인해보자\n",
        "title_result = get_all_categories()\n",
        "\n",
        "print(\"총\",len(title_result), \"개\")\n",
        "print(title_result)"
      ],
      "id": "cf231090",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 73 개\n",
            "['\\n\\n        Coreference Resolution | Speech and Language Processing(Daniel Jurafsky and James H. Martin, 2019)\\n      24 Apr 2021\\n\\n', '\\n\\n        ㅡ\\n      28 Oct 2019\\n\\n', '\\n\\n        Investigating BERT’s Knowledge of Language:Five Analysis Methods with NPIs(Warstadt et al.(2019))\\n      07 Apr 2021\\n\\n', '\\n\\n        Assessing the ability of Transformer-based Neural Models to represent structurally unbounded dependencies(Da Costa.J et al.(2020))\\n      04 Apr 2021\\n\\n', '\\n\\n        What does BERT learn about the structure of language?(Jawahar.G(2019))\\n      01 Apr 2021\\n\\n', '\\n\\n        Contextual word representation\\n      30 Mar 2021\\n\\n', '\\n\\n        A Structural Probe for Finding Syntax in Word Representations(Hewitt.J(2019))\\n      07 Mar 2021\\n\\n', '\\n\\n        Linguistic Knowledge and Transferability of Contextual Representations(Liu(2019))\\n      17 Jan 2021\\n\\n', '\\n\\n        What Can Linguistics and Deep Learning Contribute to Each Other? (Linzen et al. (2019))\\n      16 Jan 2021\\n\\n', '\\n\\n        ㅡ\\n      29 Oct 2019\\n\\n', '\\n\\n        BERT | Pre-training of Deep Bidirectional Transformers for Language Understanding\\n      22 Nov 2019\\n\\n', '\\n\\n        Transformer | Attention Is All You Need\\n      19 Nov 2019\\n\\n', '\\n\\n        Attention in sequence to sequence\\n      12 Nov 2019\\n\\n', '\\n\\n        Sequence to Sequence(Seq2Seq)\\n      11 Nov 2019\\n\\n', '\\n\\n        GloVe(Global Word Vectors)\\n      07 Nov 2019\\n\\n', '\\n\\n        FastText | Enriching Word Vectors with Subword Information\\n      07 Nov 2019\\n\\n', '\\n\\n        Word2vec | Skip-gram\\n      06 Nov 2019\\n\\n', '\\n\\n        Word2vec | CBOW(Continuous Bag Of Words Model)\\n      05 Nov 2019\\n\\n', '\\n\\n        NPLM(Neural Probabilistic Language Model)\\n      04 Nov 2019\\n\\n', '\\n\\n        Word embedding(Distributed Representation)\\n      03 Nov 2019\\n\\n', '\\n\\n        LSA(Latent Sematic Analysis)\\n      03 Nov 2019\\n\\n', '\\n\\n        How to represent words?( Word Vectors)\\n      01 Nov 2019\\n\\n', '\\n\\n        What is Natural Language Processing(NLP)?\\n      30 Oct 2019\\n\\n', '\\n\\n        CODE = TRUE | K-Means\\n      03 Aug 2021\\n\\n', '\\n\\n        L1, L2 (Norm, Loss, Regularization)\\n      04 Oct 2020\\n\\n', '\\n\\n        Transfer Learning, Multi-task Learning, End-to-End deep learning\\n      01 Oct 2020\\n\\n', '\\n\\n        Long-Distance Dependency(LDD)\\n      04 Apr 2021\\n\\n', '\\n\\n        ㅡ\\n      02 Oct 2020\\n\\n', '\\n\\n        Repair Mechanisms\\n      07 Nov 2020\\n\\n', '\\n\\n        Sequence Expansions\\n      06 Nov 2020\\n\\n', '\\n\\n        Adjacency Pair | Action and Understanding\\n      05 Nov 2020\\n\\n', '\\n\\n        Preference Structure\\n      04 Nov 2020\\n\\n', '\\n\\n        Turn-Taking\\n      03 Nov 2020\\n\\n', '\\n\\n        Conversation Analysis_Methods\\n      02 Nov 2020\\n\\n', '\\n\\n        Conversation Analysis\\n      01 Nov 2020\\n\\n', '\\n\\n        Textlinguistik\\n      14 Dec 2020\\n\\n', '\\n\\n        Pragmatik\\n      13 Dec 2020\\n\\n', '\\n\\n        Semantische Theoriebildung\\n      12 Dec 2020\\n\\n', '\\n\\n        Semantische Grundbegriffe\\n      11 Dec 2020\\n\\n', '\\n\\n        Attribute und syntaktische Einzelprobleme\\n      10 Dec 2020\\n\\n', '\\n\\n        Ergaenzungen und Angaben\\n      09 Dec 2020\\n\\n', '\\n\\n        Dependenz und Valenz\\n      08 Dec 2020\\n\\n', '\\n\\n        Traditionelle Syntaxanalyse\\n      07 Dec 2020\\n\\n', '\\n\\n        Wordbildung und Flexion\\n      06 Dec 2020\\n\\n', '\\n\\n        Morphologie\\n      05 Dec 2020\\n\\n', '\\n\\n        Phonetik und Phonologie\\n      03 Dec 2020\\n\\n', '\\n\\n        Semiotik\\n      02 Dec 2020\\n\\n', '\\n\\n        Sprache und Linguistik\\n      01 Dec 2020\\n\\n', '\\n\\n        Deutsch | Wendung2\\n      16 May 2021\\n\\n', '\\n\\n        Deutsch | Wendung\\n      25 Apr 2021\\n\\n', '\\n\\n        Deutsch | Grammatik\\n      02 Jan 2021\\n\\n', '\\n\\n        CODE = TRUE | Tensorflow\\n      03 Aug 2021\\n\\n', '\\n\\n        CODE = TRUE | Crawling1\\n      03 Aug 2021\\n\\n', '\\n\\n        Python | File input-output\\n      21 Jul 2021\\n\\n', '\\n\\n        Python | Class\\n      20 Jul 2021\\n\\n', '\\n\\n        Python | Module\\n      19 Jul 2021\\n\\n', '\\n\\n        Python | Function\\n      18 Jul 2021\\n\\n', '\\n\\n        Python | Built in function\\n      18 Jul 2021\\n\\n', '\\n\\n        Python | Exeption Handling\\n      17 Jul 2021\\n\\n', '\\n\\n        Python | Conditional/Iterative Structure\\n      16 Jul 2021\\n\\n', '\\n\\n        Python | Data Type | Dictionary\\n      15 Jul 2021\\n\\n', '\\n\\n        Python | Data Type | Tuple\\n      14 Jul 2021\\n\\n', '\\n\\n        Python | Data Type | List\\n      13 Jul 2021\\n\\n', '\\n\\n        Python | Data Type | String\\n      12 Jul 2021\\n\\n', '\\n\\n        Python | Data Type\\n      11 Jul 2021\\n\\n', '\\n\\n        Python | Calculation\\n      11 Jul 2021\\n\\n', '\\n\\n        ㅡ\\n      03 Jan 2021\\n\\n', '\\n\\n        Git | Commit Rebase\\n      10 Jul 2021\\n\\n', '\\n\\n        Git | Branch\\n      08 Jul 2021\\n\\n', '\\n\\n        Git | Repository\\n      05 Jul 2021\\n\\n', '\\n\\n        ㅡ\\n      04 Jan 2021\\n\\n', '\\n\\n        plan\\n      14 Mar 2021\\n\\n', '\\n\\n        color test\\n      24 Jan 2021\\n\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e007a52",
        "outputId": "fdb6a5d1-8005-43b1-a0a6-9346a52376fd"
      },
      "source": [
        "'''\n",
        "뽑아보니까 좀 어수선하다. 정리하자\n",
        "# 1. title_result에 담긴 배열을 하나씩 돌면서 \n",
        "# 2. 왼쪽에 있는 \\n\\n        \"를 지우고 title_result3에 담는다\n",
        "# 3. title_result3에서 오른쪽에 있는 \"\\n\\n\"를 지우고 title_result4에 담는다.\n",
        "# 4. print함수는 마지막에 '\\n'이 기본으로 출력되기 때문에 \n",
        "#    end=''로 마지막에 줄바꿈 없이 끝낸다고 표시한다.\n",
        "'''\n",
        "for title_result2 in title_result: # 1\n",
        "    title_result3 = title_result2.lstrip(\"\\n\\n        \") # 2\n",
        "    title_result4 = title_result3.rstrip(\"\\n\\n\") #3\n",
        "    print(title_result4, end='') # 4"
      ],
      "id": "2e007a52",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coreference Resolution | Speech and Language Processing(Daniel Jurafsky and James H. Martin, 2019)\n",
            "      24 Apr 2021\n",
            "ㅡ\n",
            "      28 Oct 2019\n",
            "Investigating BERT’s Knowledge of Language:Five Analysis Methods with NPIs(Warstadt et al.(2019))\n",
            "      07 Apr 2021\n",
            "Assessing the ability of Transformer-based Neural Models to represent structurally unbounded dependencies(Da Costa.J et al.(2020))\n",
            "      04 Apr 2021\n",
            "What does BERT learn about the structure of language?(Jawahar.G(2019))\n",
            "      01 Apr 2021\n",
            "Contextual word representation\n",
            "      30 Mar 2021\n",
            "A Structural Probe for Finding Syntax in Word Representations(Hewitt.J(2019))\n",
            "      07 Mar 2021\n",
            "Linguistic Knowledge and Transferability of Contextual Representations(Liu(2019))\n",
            "      17 Jan 2021\n",
            "What Can Linguistics and Deep Learning Contribute to Each Other? (Linzen et al. (2019))\n",
            "      16 Jan 2021\n",
            "ㅡ\n",
            "      29 Oct 2019\n",
            "BERT | Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
            "      22 Nov 2019\n",
            "Transformer | Attention Is All You Need\n",
            "      19 Nov 2019\n",
            "Attention in sequence to sequence\n",
            "      12 Nov 2019\n",
            "Sequence to Sequence(Seq2Seq)\n",
            "      11 Nov 2019\n",
            "GloVe(Global Word Vectors)\n",
            "      07 Nov 2019\n",
            "FastText | Enriching Word Vectors with Subword Information\n",
            "      07 Nov 2019\n",
            "Word2vec | Skip-gram\n",
            "      06 Nov 2019\n",
            "Word2vec | CBOW(Continuous Bag Of Words Model)\n",
            "      05 Nov 2019\n",
            "NPLM(Neural Probabilistic Language Model)\n",
            "      04 Nov 2019\n",
            "Word embedding(Distributed Representation)\n",
            "      03 Nov 2019\n",
            "LSA(Latent Sematic Analysis)\n",
            "      03 Nov 2019\n",
            "How to represent words?( Word Vectors)\n",
            "      01 Nov 2019\n",
            "What is Natural Language Processing(NLP)?\n",
            "      30 Oct 2019\n",
            "CODE = TRUE | K-Means\n",
            "      03 Aug 2021\n",
            "L1, L2 (Norm, Loss, Regularization)\n",
            "      04 Oct 2020\n",
            "Transfer Learning, Multi-task Learning, End-to-End deep learning\n",
            "      01 Oct 2020\n",
            "Long-Distance Dependency(LDD)\n",
            "      04 Apr 2021\n",
            "ㅡ\n",
            "      02 Oct 2020\n",
            "Repair Mechanisms\n",
            "      07 Nov 2020\n",
            "Sequence Expansions\n",
            "      06 Nov 2020\n",
            "Adjacency Pair | Action and Understanding\n",
            "      05 Nov 2020\n",
            "Preference Structure\n",
            "      04 Nov 2020\n",
            "Turn-Taking\n",
            "      03 Nov 2020\n",
            "Conversation Analysis_Methods\n",
            "      02 Nov 2020\n",
            "Conversation Analysis\n",
            "      01 Nov 2020\n",
            "Textlinguistik\n",
            "      14 Dec 2020\n",
            "Pragmatik\n",
            "      13 Dec 2020\n",
            "Semantische Theoriebildung\n",
            "      12 Dec 2020\n",
            "Semantische Grundbegriffe\n",
            "      11 Dec 2020\n",
            "Attribute und syntaktische Einzelprobleme\n",
            "      10 Dec 2020\n",
            "Ergaenzungen und Angaben\n",
            "      09 Dec 2020\n",
            "Dependenz und Valenz\n",
            "      08 Dec 2020\n",
            "Traditionelle Syntaxanalyse\n",
            "      07 Dec 2020\n",
            "Wordbildung und Flexion\n",
            "      06 Dec 2020\n",
            "Morphologie\n",
            "      05 Dec 2020\n",
            "Phonetik und Phonologie\n",
            "      03 Dec 2020\n",
            "Semiotik\n",
            "      02 Dec 2020\n",
            "Sprache und Linguistik\n",
            "      01 Dec 2020\n",
            "Deutsch | Wendung2\n",
            "      16 May 2021\n",
            "Deutsch | Wendung\n",
            "      25 Apr 2021\n",
            "Deutsch | Grammatik\n",
            "      02 Jan 2021\n",
            "CODE = TRUE | Tensorflow\n",
            "      03 Aug 2021\n",
            "CODE = TRUE | Crawling1\n",
            "      03 Aug 2021\n",
            "Python | File input-output\n",
            "      21 Jul 2021\n",
            "Python | Class\n",
            "      20 Jul 2021\n",
            "Python | Module\n",
            "      19 Jul 2021\n",
            "Python | Function\n",
            "      18 Jul 2021\n",
            "Python | Built in function\n",
            "      18 Jul 2021\n",
            "Python | Exeption Handling\n",
            "      17 Jul 2021\n",
            "Python | Conditional/Iterative Structure\n",
            "      16 Jul 2021\n",
            "Python | Data Type | Dictionary\n",
            "      15 Jul 2021\n",
            "Python | Data Type | Tuple\n",
            "      14 Jul 2021\n",
            "Python | Data Type | List\n",
            "      13 Jul 2021\n",
            "Python | Data Type | String\n",
            "      12 Jul 2021\n",
            "Python | Data Type\n",
            "      11 Jul 2021\n",
            "Python | Calculation\n",
            "      11 Jul 2021\n",
            "ㅡ\n",
            "      03 Jan 2021\n",
            "Git | Commit Rebase\n",
            "      10 Jul 2021\n",
            "Git | Branch\n",
            "      08 Jul 2021\n",
            "Git | Repository\n",
            "      05 Jul 2021\n",
            "ㅡ\n",
            "      04 Jan 2021\n",
            "plan\n",
            "      14 Mar 2021\n",
            "color test\n",
            "      24 Jan 2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9500b96"
      },
      "source": [
        ""
      ],
      "id": "a9500b96",
      "execution_count": null,
      "outputs": []
    }
  ]
}